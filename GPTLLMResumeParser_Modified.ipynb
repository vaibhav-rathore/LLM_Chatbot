{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ML\\CHROMA\\TCSParsing\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\ML\\CHROMA\\TCSParsing\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "env_path = '.env'\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "load_dotenv(env_path)\n",
    "from datetime import datetime\n",
    "from langchain_core.pydantic_v1 import constr, BaseModel, Field, validator\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage,AIMessage\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.tools import StructuredTool\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Literal, Optional, List, Dict, Any\n",
    "from langchain_core.tools import tool\n",
    "import functools\n",
    "import pandas as pd\n",
    "import pymupdf4llm\n",
    "from docx import Document\n",
    "import win32com.client\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(temperature=0.7,\n",
    "                        api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "                        azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "                        openai_api_version=os.getenv('AZURE_OPENAI_VERSION'),\n",
    "                        azure_deployment=os.getenv('AZURE_GPT35_MODEL')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CountryCode(BaseModel):\n",
    "    IsoAlpha2: Optional[str]\n",
    "    IsoAlpha3: Optional[str]\n",
    "    UNCode: Optional[str]\n",
    "\n",
    "class ResumeCountry(BaseModel):\n",
    "    Country: Optional[str]\n",
    "    Evidence: Optional[str]\n",
    "    CountryCode: Optional[CountryCode]\n",
    "\n",
    "class Email(BaseModel):\n",
    "    EmailAddress: str\n",
    "    ConfidenceScore: int\n",
    "\n",
    "class PhoneNumber(BaseModel):\n",
    "    Number: str\n",
    "    ISDCode: str\n",
    "    OriginalNumber: str\n",
    "    FormattedNumber: str\n",
    "    Type: str\n",
    "    ConfidenceScore: int\n",
    "\n",
    "class Name(BaseModel):\n",
    "    FullName: str\n",
    "    TitleName: str\n",
    "    FirstName: str\n",
    "    MiddleName: str\n",
    "    LastName: str\n",
    "    FormattedName: str\n",
    "    ConfidenceScore: int\n",
    "\n",
    "class Address(BaseModel):\n",
    "    City: Optional[str]\n",
    "    State: Optional[str]\n",
    "    StateIsoCode: Optional[str]\n",
    "    Country: Optional[str]\n",
    "    CountryCode: Optional[CountryCode]\n",
    "    FormattedAddress: Optional[str]\n",
    "    Type: Optional[str]\n",
    "    ConfidenceScore: Optional[int]\n",
    "\n",
    "class Degree(BaseModel):\n",
    "    DegreeName: str\n",
    "    NormalizeDegree: str\n",
    "    Specialization: List[str]\n",
    "    ConfidenceScore: int\n",
    "\n",
    "class Institution(BaseModel):\n",
    "    Name: str\n",
    "    Type: str\n",
    "    Location: Address\n",
    "    ConfidenceScore: int\n",
    "\n",
    "class SegregatedQualification(BaseModel):\n",
    "    Institution: Institution\n",
    "    Degree: Degree\n",
    "    FormattedDegreePeriod: str\n",
    "    StartDate: str\n",
    "    EndDate: str\n",
    "\n",
    "class SegregatedSkill(BaseModel):\n",
    "    Skill: str\n",
    "    Type: str\n",
    "    ExperienceInMonths: int\n",
    "    LastUsed: Optional[str]\n",
    "    Evidence: Optional[str]\n",
    "\n",
    "class SegregatedExperience(BaseModel):\n",
    "    EmployerName: str\n",
    "    JobTitle: str\n",
    "    JobDescription: str\n",
    "    City: Optional[str]\n",
    "    State: Optional[str]\n",
    "    Country: Optional[str]\n",
    "    StartDate: str\n",
    "    EndDate: Optional[str]\n",
    "\n",
    "class ResumeParserData(BaseModel):\n",
    "    ResumeFileName: str\n",
    "    ResumeLanguage: dict\n",
    "    ParsingDate: str\n",
    "    ResumeCountry: ResumeCountry\n",
    "    Name: Name\n",
    "    DateOfBirth: Optional[str]\n",
    "    Email: List[Email]\n",
    "    PhoneNumber: List[PhoneNumber]\n",
    "    Address: List[Address]\n",
    "    SegregatedQualification: List[SegregatedQualification]\n",
    "    SegregatedSkill: List[SegregatedSkill]\n",
    "    SegregatedExperience: List[SegregatedExperience]\n",
    "    Certification: Optional[str]\n",
    "    Summary: Optional[str]\n",
    "\n",
    "class FinalOutput(BaseModel):\n",
    "    ResumeParserData: ResumeParserData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ML\\CHROMA\\TCSParsing\\.venv\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1534: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "strctured_llm = llm.with_structured_output(schema=FinalOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_txt_convertor(file_path_name):\n",
    "    \"\"\"\n",
    "    Converting pdf to Markdown text.\n",
    "    Text is provided to LLM for exraction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_text = pymupdf4llm.to_markdown(file_path_name)\n",
    "        return md_text\n",
    "    except Exception as e:\n",
    "        print(f'pdf extraction error {file_path_name}:{e}')\n",
    "        return None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docx_to_txt_convertor(file_path_name):\n",
    "    \"\"\"\n",
    "    Converting doc to text.\n",
    "    Text is provided to LLM for exraction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = Document(file_path_name)\n",
    "        full_txt = []\n",
    "        for paragraph in doc.paragraphs:\n",
    "            full_txt.append(paragraph.text)\n",
    "        return '\\n'.join(full_txt)\n",
    "    except Exception as e:\n",
    "        print(f'Docx Conversion Error:{file_path_name}:{e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef doc_to_txt_convertor(file_path_name):\\n    \"\"\"\\n    Converting doc to text.\\n    Text is provided to LLM for exraction\\n    \"\"\"\\n    try:\\n        word = win32com.client.Dispatch(\\'word.Application\\')\\n        word.visile = False\\n        doc = word.Docment.open(file_path_name)\\n        txt = doc.Content.Text\\n        doc.Close()\\n        word.Quit()\\n    except Exception as e:\\n        print(f\\'Doc Conversion Error:{file_path_name}:{e}\\')\\n        return None\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def doc_to_txt_convertor(file_path_name):\n",
    "    \"\"\"\n",
    "    Converting doc to text.\n",
    "    Text is provided to LLM for exraction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        word = win32com.client.Dispatch('word.Application')\n",
    "        word.visile = False\n",
    "        doc = word.Docment.open(file_path_name)\n",
    "        txt = doc.Content.Text\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "    except Exception as e:\n",
    "        print(f'Doc Conversion Error:{file_path_name}:{e}')\n",
    "        return None\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt_from_resume(file_path_name):\n",
    "    try:\n",
    "        if file_path_name.endswith('.pdf'):\n",
    "            return pdf_to_txt_convertor(file_path_name)\n",
    "        elif file_path_name.endswith('.docx'):\n",
    "            return docx_to_txt_convertor(file_path_name)\n",
    "        else:\n",
    "            print(f'unsuported file format: {file_path_name}')\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f'Resume text extraction error:{e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are specialized agent to provide extracted information from resume.\"\n",
    "        \"If the value is not known fillvalue with null.\"\n",
    "        \"Do not make or create or generate any information which is not provided\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\",\"{text}\"\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"text\":extract_txt_from_resume(\"john doe.pdf\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = strctured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = llm_response.dict()\n",
    "response_json = json.dumps(response_dict,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"John Doe\",\n",
      "    \"contact\": \"+91-9008198377\",\n",
      "    \"email\": \"john.doe@hotmail.com\",\n",
      "    \"dob\": null,\n",
      "    \"address\": \"Mumbai\",\n",
      "    \"job_role\": null,\n",
      "    \"skills\": null,\n",
      "    \"years_of_experience\": null,\n",
      "    \"company\": null,\n",
      "    \"education\": null,\n",
      "    \"education_institute\": null,\n",
      "    \"education_year\": null,\n",
      "    \"education_degree\": null,\n",
      "    \"course_startdate\": null,\n",
      "    \"course_enddate\": null,\n",
      "    \"certification\": null,\n",
      "    \"number_of_certifications\": null,\n",
      "    \"awards\": null,\n",
      "    \"refernces\": null,\n",
      "    \"miscellaneous\": null,\n",
      "    \"summary\": \"John Doe is a highly experienced professional with 19 years of international leadership experience in project and process management. He is skilled in procurement solutions, category management, sourcing, and supplier relationship management. John holds a Master's in Information Management from Jamnalal Bajaj Institute of Management Studies, a Bachelor of Computer Application from Madurai Kamaraj University, and a Diploma in Electronics & Communication Engineering from Bharati Vidyapeeth of Technology. He is certified in various areas including PMP, CSPO, Prince 2 Agile, Lean Six Sigma Black Belt, and CPSM. John has a strong background in IT solutions and services, leading teams in procurement, category management, and analytics. He has worked with Fortune 500 clients and is proficient in tools like Microsoft Power BI, Power Apps, and Vue.js. John has held key positions such as Lead Product Owner, General Manager, Head of Auxiliary Equipment, and Deputy General Manager in his career.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e45c3c74fc05f4d590ea89f7a8750fbaf7b46c0d006137d790f8d5af3f141ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
